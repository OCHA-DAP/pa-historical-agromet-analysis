{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download CHIRTS Data from IRI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHIRTSmax is a monthly 0.05 degree semi-global (60S-70N) gridded dataset describing monthly averages of daily maximum 2m air temperatures (Tmax). The CHIRTSmax combines three separate components: \n",
    "\n",
    "1. a static high resolution (0.05) background Tmax climatology describing average 1981-2010 air temperature conditions at each location, \n",
    "2. time-varying 0.05 degree satellite thermal infrared-based estimates of monthly Tmax anomalies, and \n",
    "3. time-varying 0.05 degree 2m Tmax anomalies based on interpolated station observations. \n",
    "\n",
    "More information [here](https://earlywarning.usgs.gov/fews/product/620)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import geopandas as gpd\n",
    "import rioxarray as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(os.getenv(\"HAM_DIR\")) / \"temperature/\"\n",
    "mon_chirts_dir = data_dir / \"monthly_chirts/\"\n",
    "shp_dir = Path(os.getenv(\"AA_DATA_DIR\")) / \"public/raw/ner/cod_ab/ner_cod_ab/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16625  , 11.69697  , 15.99564  , 23.5331862])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_shp_adm0 = gpd.read_file(shp_dir / \"adm0.shp.zip\")\n",
    "ner_shp_adm0.total_bounds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells take a lot of time to download as they are daily values. Looking for monthly values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL_Tmax = \"https://iridl.ldeo.columbia.edu/SOURCES/.UCSB/.CHIRTS/.v1.0/.daily/.global/.0p05/.tmax/X/%280.1E%29%2816E%29RANGEEDGES/Y/%2811.6N%29%2823.6N%29RANGEEDGES/ngridtable/4+ncoltable.html?tabopt.N=5&tabopt.1=text&tabopt.2=text&tabopt.3=text&tabopt.4=text&tabopt.5=blankNaN&NaNmarker=&tabtype=csv&eol=CR-LF+%28DOS%2FWindows%29&filename=datafile.csv\"\n",
    "# URL_Tmax = \"https://iridl.ldeo.columbia.edu/SOURCES/.UCSB/.CHIRTS/.v1.0/.daily/.global/.0p05/.tmax/X/%280.1E%29%2816E%29RANGEEDGES/Y/%2811.6N%29%2823.6NN%29RANGEEDGES/T/%281%20Jan%201983%29%2831%20Dec%202016%29RANGEEDGES/T/%281%20Jan%201983%29%2831%20Dec%202016%29RANGEEDGES/[Y+X]datatable.tsv\"\n",
    "# response_tmax = requests.get(URL_Tmax)\n",
    "# open(data_dir / \"CHIRTSTmaxdatafile.tsv\", \"wb\").write(response_tmax.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL_Tmin = \"https://iridl.ldeo.columbia.edu/SOURCES/.UCSB/.CHIRTS/.v1.0/.daily/.global/.0p05/.tmin/X/%280.1E%29%2816E%29RANGEEDGES/Y/%2811.6N%29%2823.6N%29RANGEEDGES/ngridtable/4+ncoltable.html?tabopt.N=5&tabopt.1=text&tabopt.2=text&tabopt.3=text&tabopt.4=text&tabopt.5=blankNaN&NaNmarker=&tabtype=csv&eol=CR-LF+%28DOS%2FWindows%29&filename=datafile.csv\"\n",
    "# URL_Tmin = \"https://iridl.ldeo.columbia.edu/SOURCES/.UCSB/.CHIRTS/.v1.0/.daily/.global/.0p05/.tmin/X/%280.1E%29%2816E%29RANGEEDGES/Y/%2811.6N%29%2823.6N%29RANGEEDGES/[Y+X]datatable.tsv\"\n",
    "# response_tmin = requests.get(URL_Tmin)\n",
    "# open(data_dir / \"CHIRTSTmindatafile.tsv\", \"wb\").write(response_tmin.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell can download monthly values and rasters clipped based on bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauni\\Desktop\\Work\\OCHA\\GitHub\\VirtualEnv\\hamenv\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'edcintl.cr.usgs.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Alternative Source\n",
    "# This data is global\n",
    "URL = \"https://edcintl.cr.usgs.gov/downloads/sciweb1/shared/fews/web/global/monthly/chirts/tmax/downloads/monthly/\"\n",
    "\n",
    "\n",
    "def list_files(URL, ext):\n",
    "    page = requests.get(URL, verify=False).text\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    for node in soup.find_all(\"a\"):\n",
    "        if node.get(\"href\").endswith(ext):\n",
    "            file_url = [\n",
    "                URL + \"/\" + node.get(\"href\")\n",
    "                for node in soup.find_all(\"a\")\n",
    "                if node.get(\"href\").endswith(ext)\n",
    "            ]\n",
    "            file_list = [\n",
    "                node.get(\"href\")\n",
    "                for node in soup.find_all(\"a\")\n",
    "                if node.get(\"href\").endswith(ext)\n",
    "            ]\n",
    "    return file_list\n",
    "\n",
    "\n",
    "chirts_file_list = list_files(URL=URL, ext=\"tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this clips the raster file to only Niger bounds\n",
    "for file in chirts_file_list:\n",
    "    if file in chirts_file_list:\n",
    "        input_raster = rio.open_rasterio(URL + file)\n",
    "        rast_clip = input_raster.rio.clip_box(*ner_shp_adm0.total_bounds)\n",
    "        rast_clip.rio.to_raster(mon_chirts_dir / file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this downloads the global dataset\n",
    "# for file in chirts_file_list:\n",
    "#    if file in chirts_file_list:\n",
    "#        req = requests.get(URL + file, verify=False, stream=True)\n",
    "#        open(data_dir / file, \"wb\").write(req.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hamenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

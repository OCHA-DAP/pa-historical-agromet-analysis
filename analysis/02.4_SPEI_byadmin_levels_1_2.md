---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.14.5
  kernelspec:
    display_name: hamenv
    language: python
    name: python3
---

# Converting SPEI Values to Admin 1 and Admin 2

```python
%load_ext jupyter_black
import os
from pathlib import Path
import pandas as pd
import geopandas as gpd
import rasterio
import rioxarray as rxr
from rasterstats import zonal_stats
```

```python
data_dir = Path(os.getenv("HAM_DIR")) / "evapotranspiration/"
shp_dir = Path(os.getenv("AA_DATA_DIR")) / "public/raw/ner/cod_ab/ner_cod_ab/"
shp_dir_clp = Path(os.getenv("HAM_DIR")) / "clipped_codab/"
```

```python
ner_shp_adm0 = gpd.read_file(shp_dir / "adm0.shp.zip")
ner_shp_adm1 = gpd.read_file(shp_dir / "adm1.shp.zip")
ner_shp_adm2 = gpd.read_file(shp_dir / "adm2.shp.zip")
```

```python
# clipped adm1 and adm2
ner_shp_adm0_clipped = gpd.read_file(shp_dir_clp / "ner_codab_adm0_clipped_17N.gpkg")
ner_shp_adm1_clipped = gpd.read_file(shp_dir_clp / "ner_codab_adm1_clipped_17N.gpkg")
ner_shp_adm2_clipped = gpd.read_file(shp_dir_clp / "ner_codab_adm2_clipped_17N.gpkg")
```

```python
ner_shp_adm0.total_bounds
```

```python
spei_data = rxr.open_rasterio(data_dir / "SPEIdatafile.nc")
spei_data
```

```python
months = spei_data["time"].values
months
```

```python
print(spei_data.dims)
print(spei_data.attrs)
print(spei_data.coords)
```

```python
spei_data.sel(time=months[0]).values
```

```python
spei_affine = rasterio.open(data_dir / "SPEIdatafile.nc").transform
```

```python
spei_affine
```

```python
def aggregating_admin(geodf, admID1, admID2):
    adm_spei_df = pd.DataFrame()
    for mon in months:
        spei_arr = spei_data.sel(time=mon).values
        summary_stats = zonal_stats(
            geodf,
            spei_arr,
            stats=["mean", "median"],
            nodata=-9999,
            all_touched=True,
            affine=spei_affine,
        )
        adm_stats = pd.DataFrame(summary_stats)
        file_df = pd.merge(
            geodf[[admID1, admID2]],
            adm_stats,
            left_index=True,
            right_index=True,
        )
        file_df["date"] = f"{mon.year:04}" + "-" + f"{mon.month:02}"
        adm_spei_df = pd.concat([adm_spei_df, file_df], axis=0)
    return adm_spei_df
```

## Admin 0

```python
ner_shp_adm0.drop(
    ["OBJECTID", "Shape_Leng", "Shape_Area", "ISO2"], axis=1, inplace=True
)
adm0_spei_df = aggregating_admin(geodf=ner_shp_adm0, admID1="ISO3", admID2="NOMPAY"
)
adm0_spei_df.to_csv(data_dir / "ner_adm0_spei.csv", index=False)
```

```python
adm0_chirts_df = aggregating_admin(geodf=ner_shp_adm0_clipped, admID1="ISO3", admID2="NOMPAY")
adm0_spei_df.to_csv(data_dir / "ner_adm0_clipped_spei.csv", index=False)
```

## Admin 1

```python
ner_shp_adm1.drop(
    ["OBJECTID", "Shape_Leng", "Shape_Area", "ISO3", "ISO2"], axis=1, inplace=True
)
ner_shp_adm1
```

### For areas not clipped

```python
adm1_spei_df = aggregating_admin(geodf=ner_shp_adm1, admID1="rowcacode1", admID2="NOMREG")
```

```python
adm1_spei_df.to_csv(data_dir / "ner_adm1_spei.csv", index=False)
```

### For clipped areas

```python
adm1_spei_df = aggregating_admin(geodf=ner_shp_adm1_clipped, admID1="rowcacode1", admID2="NOMREG")

adm1_spei_df.to_csv(data_dir / "ner_adm1_clipped_spei.csv", index=False)
```

## Admin 2

```python
ner_shp_adm2.drop(
    ["OBJECTID", "Shape_Leng", "Shape_Area", "adm_01", "rowcacode1", "ISO3", "ISO2"],
    axis=1,
    inplace=True,
)
ner_shp_adm2
```

### For areas not clipped

```python
adm2_spei_df = aggregating_admin(geodf=ner_shp_adm2, admID1="rowcacode2", admID2="NOMDEP")
```

```python
adm2_spei_df.to_csv(data_dir / "ner_adm2_spei.csv", index=False)
```

### For clipped areas

```python
ner_adm2_clipped_geom = ner_shp_adm2_clipped[
    ner_shp_adm2_clipped["geometry"] != None
].reset_index(drop=True)
```

```python
adm2_spei_df = aggregating_admin(geodf=ner_shp_adm2_clipped, admID1="rowcacode2", admID2="NOMDEP")

adm2_spei_df.to_csv(data_dir / "ner_adm2_clipped_spei.csv", index=False)
```
